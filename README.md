# ğŸ§  RAG-Based PDF Chatbot using Gemini & FAISS

ğŸš€ **Live Application:**
ğŸ‘‰ [https://rag-based-use-chatbot.streamlit.app/](https://rag-based-use-chatbot.streamlit.app/)

A **Retrieval-Augmented Generation (RAG)** powered chatbot that allows users to upload PDF documents and ask natural language questions, receiving **accurate, context-aware answers** grounded in the document content.

This project demonstrates an **end-to-end Generative AI pipeline** combining **LLMs, vector databases, embeddings, and a Streamlit UI**, built to production-ready standards.

---

## ğŸ¯ Why This Project Stands Out

* âœ… Real-world **RAG architecture** implementation
* âœ… Uses **FAISS** for fast semantic vector search
* âœ… Powered by **Google Gemini LLM**
* âœ… Handles real **PDF documents**
* âœ… Secure API key handling using `.env`
* âœ… Live deployed Streamlit application
* âœ… Clean, modular, and interview-ready codebase

---

## ğŸ§© Application Workflow (RAG Pipeline)

1. **PDF Upload**
   User uploads a PDF document via the Streamlit sidebar

2. **Text Extraction**
   Text is extracted using a custom PDF extractor

3. **Chunking**
   Text is split into overlapping chunks using `RecursiveCharacterTextSplitter`

4. **Embedding Generation**
   Chunks are converted into embeddings using **HuggingFace MiniLM**

5. **Vector Storage**
   Embeddings are stored in a **FAISS vector database**

6. **Retrieval**
   Relevant document chunks are retrieved based on the user query

7. **Answer Generation**
   Retrieved context is passed to **Gemini LLM** to generate grounded responses

---

## ğŸ› ï¸ Tech Stack

| Category               | Technology                            |
| ---------------------- | ------------------------------------- |
| Programming Language   | Python                                |
| UI Framework           | Streamlit                             |
| LLM                    | Google Gemini (gemini-2.5-flash-lite) |
| Vector Database        | FAISS                                 |
| Embeddings             | HuggingFace (all-MiniLM-L6-v2)        |
| Framework              | LangChain                             |
| PDF Processing         | PyPDF                                 |
| Environment Management | python-dotenv                         |

---

## ğŸ“ Project Structure

```text
RAG-Based-Chatbot/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ pdfextractor.py         # Custom PDF text extraction logic
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ .env                    # Environment variables (ignored by Git)
â””â”€â”€ README.md               # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/RAG-Based-Chatbot.git
cd RAG-Based-Chatbot
```

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux / Mac
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory:

```env
GOOGLE_API_KEY=your_google_gemini_api_key
```

âš ï¸ **Do NOT commit `.env` to GitHub**

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

Open your browser at:

```
http://localhost:8501
```

---

## ğŸ§ª How to Use

1. Upload a **PDF document**
2. Enter your question in the chat input
3. Receive **context-aware answers** from the chatbot
4. Continue the conversation with maintained chat history

---

## ğŸ’¡ Use Cases

* ğŸ“„ Research paper Q&A
* ğŸ“š Study material assistant
* ğŸ§¾ Policy and document analysis
* ğŸ“ Academic learning support
* ğŸ“‘ Resume or report understanding

---

## ğŸ” Security Best Practices

* API keys stored securely using environment variables
* `.env` file excluded via `.gitignore`
* No sensitive data logged or persisted

---

## ğŸ“Œ Resume Bullet Points (ATS Optimized)

* Built a **Retrieval-Augmented Generation (RAG)** chatbot enabling PDF-based question answering using **Gemini LLM**.
* Implemented **semantic search** with **FAISS** and **HuggingFace MiniLM embeddings** for accurate document retrieval.
* Developed a complete **PDF processing pipeline** including text extraction, chunking, embedding, retrieval, and generation.
* Designed an interactive **Streamlit UI** with chat history and real-time responses.
* Applied secure credential management using **dotenv** and environment variables.
* Deployed a production-ready **GenAI application** demonstrating real-world LLM usage.

---

## ğŸš€ Future Enhancements

* Multi-PDF document support
* Source citation with page numbers
* Persistent chat memory
* User authentication
* Cloud-based vector storage

---

## ğŸ‘©â€ğŸ’» Author

**Alisha Verma**
MCA | Data Analytics | GenAI Enthusiast
AWS Certified | Python | SQL | Cloud | AI

ğŸ“« *Open to Data Analyst / GenAI / Cloud opportunities*

---

â­ *If you found this project useful, feel free to star the repository!*
